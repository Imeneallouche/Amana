{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnsZxlAkjssb",
        "outputId": "88a98d9e-b07c-4af5-a175-901540022843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names in dataset: Index(['description', 'category', 'deadline_proximity', 'vulnerability_score',\n",
            "       'urgency_label'],\n",
            "      dtype='object')\n",
            "Warning: Found NaN values in 'urgency_label'. Replacing with default value (e.g., 0).\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.3298 - loss: 1.1161 - val_accuracy: 0.2530 - val_loss: 1.1071\n",
            "Epoch 2/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.3157 - loss: 1.0984 - val_accuracy: 0.2450 - val_loss: 1.1134\n",
            "Epoch 3/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.3230 - loss: 1.1005 - val_accuracy: 0.2490 - val_loss: 1.1045\n",
            "Epoch 4/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.3215 - loss: 1.0989 - val_accuracy: 0.2750 - val_loss: 1.1061\n",
            "Epoch 5/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.3279 - loss: 1.1000 - val_accuracy: 0.4150 - val_loss: 1.0895\n",
            "Epoch 6/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.3886 - loss: 1.0933 - val_accuracy: 0.2430 - val_loss: 1.1084\n",
            "Epoch 7/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.3107 - loss: 1.1006 - val_accuracy: 0.2560 - val_loss: 1.1103\n",
            "Epoch 8/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 0.3076 - loss: 1.1081 - val_accuracy: 0.2490 - val_loss: 1.1130\n",
            "Epoch 9/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.3137 - loss: 1.1049 - val_accuracy: 0.2730 - val_loss: 1.1013\n",
            "Epoch 10/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.3910 - loss: 1.0939 - val_accuracy: 0.3060 - val_loss: 1.0995\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4200 - loss: 1.0892\n",
            "Test Accuracy: 0.4150\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4200 - loss: 1.0892\n",
            "ðŸ”¥ Final Test Accuracy: 0.4150\n",
            "Column names in new test dataset: Index(['description', 'category', 'deadline_proximity', 'vulnerability_score',\n",
            "       'urgency_label'],\n",
            "      dtype='object')\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4517 - loss: 1.0885\n",
            "ðŸš€ Accuracy on New Test Data: 0.4600\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 213ms/step\n",
            "âœ… Model evaluation results saved to 'model_evaluation_results.csv'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "file_path = 'urgency_train_data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Column names in dataset:\", data.columns)\n",
        "\n",
        "# Preprocess text & labels\n",
        "texts = data['description'].astype(str).tolist()\n",
        "# Convert categorical urgency labels to numerical values\n",
        "label_mapping = {'Low': 0, 'Medium': 1, 'High': 2}  # Modify if needed\n",
        "data['urgency_label'] = data['urgency_label'].map(label_mapping)\n",
        "# Check for NaN values and handle them\n",
        "if data['urgency_label'].isna().sum() > 0:\n",
        "    print(\"Warning: Found NaN values in 'urgency_label'. Replacing with default value (e.g., 0).\")\n",
        "    data['urgency_label'] = data['urgency_label'].fillna(0)  # You can choose another default\n",
        "\n",
        "# Now convert to numpy array\n",
        "labels = data['urgency_label'].astype(int).values\n",
        "\n",
        "# Tokenization\n",
        "num_words = 10000  # Increased vocabulary size\n",
        "tokenizer = Tokenizer(num_words=num_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "X = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Load GloVe embeddings\n",
        "embedding_dim = 200\n",
        "glove_path = 'glove.6B.200d.txt'  # Make sure to have this file\n",
        "glove_embeddings = {}\n",
        "with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_embeddings[word] = vector\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index < num_words:\n",
        "        vector = glove_embeddings.get(word)\n",
        "        if vector is not None:\n",
        "            embedding_matrix[index] = vector\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(num_words, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.5),\n",
        "    LSTM(64),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(np.unique(y)), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model with early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32,\n",
        "          class_weight=class_weight_dict, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Evaluate Model on Test Data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'ðŸ”¥ Final Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# ================================\n",
        "# ðŸ”¹ Load & Evaluate on New Test Data\n",
        "# ================================\n",
        "new_test_file = 'urgency_test_data.csv'\n",
        "new_test_data = pd.read_csv(new_test_file)\n",
        "\n",
        "# Check column names\n",
        "print(\"Column names in new test dataset:\", new_test_data.columns)\n",
        "\n",
        "# Preprocess text (tokenize & pad sequences)\n",
        "new_texts = new_test_data['description'].astype(str).tolist()\n",
        "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
        "new_X = pad_sequences(new_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Convert categorical labels\n",
        "new_test_data['urgency_label'] = new_test_data['urgency_label'].map(label_mapping)\n",
        "new_test_data['urgency_label'] = new_test_data['urgency_label'].fillna(0).astype(int)\n",
        "new_y = new_test_data['urgency_label'].values\n",
        "\n",
        "# Evaluate on the new test dataset\n",
        "new_test_loss, new_test_acc = model.evaluate(new_X, new_y)\n",
        "print(f'ðŸš€ Accuracy on New Test Data: {new_test_acc:.4f}')\n",
        "\n",
        "# ================================\n",
        "# ðŸ”¹ (Optional) Save Predictions for Analysis\n",
        "# ================================\n",
        "predictions = model.predict(new_X)\n",
        "predicted_labels = np.argmax(predictions, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# Compare actual vs. predicted labels\n",
        "comparison_df = pd.DataFrame({\n",
        "    'description': new_texts,\n",
        "    'actual_label': new_y,\n",
        "    'predicted_label': predicted_labels\n",
        "})\n",
        "\n",
        "# Save results to CSV\n",
        "comparison_df.to_csv('model_evaluation_results.csv', index=False)\n",
        "print(\"âœ… Model evaluation results saved to 'model_evaluation_results.csv'\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}